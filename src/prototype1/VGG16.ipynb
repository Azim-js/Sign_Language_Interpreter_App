{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import utils,callbacks\n",
    "from keras.models import Sequential,Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers.core import Dropout,Flatten,Dense\n",
    "from keras.layers.convolutional import Convolution2D,MaxPooling2D,ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input,decode_predictions\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=r\"D:\\jupyternotebooks\\prototype 1\\asl_alphabet_train\\asl_alphabet_train\"\n",
    "test_dir=r\"D:\\jupyternotebooks\\prototype 1\\asl_alphabet_test\\asl_alphabet_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=29\n",
    "batch=256\n",
    "epochs=10\n",
    "lnr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78300 images belonging to 29 classes.\n",
      "Found 8700 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "img_gen=ImageDataGenerator(rescale=1./255,validation_split=0.1)\n",
    "train=img_gen.flow_from_directory(train_dir,target_size=(64,64),subset=\"training\")\n",
    "eval=img_gen.flow_from_directory(train_dir,target_size=(64,64),subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=Adam(learning_rate=lnr)\n",
    "model=Sequential()\n",
    "model.add(VGG16(weights='imagenet',include_top=False,input_shape=(64,64,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(29,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2447/2447 [==============================] - 1870s 753ms/step - loss: 0.5751 - accuracy: 0.8295 - val_loss: 0.1062 - val_accuracy: 0.9709\n",
      "Epoch 2/10\n",
      "2447/2447 [==============================] - 889s 363ms/step - loss: 0.0197 - accuracy: 0.9949 - val_loss: 0.1397 - val_accuracy: 0.9661\n",
      "Epoch 3/10\n",
      "2447/2447 [==============================] - 801s 327ms/step - loss: 0.0211 - accuracy: 0.9948 - val_loss: 0.4334 - val_accuracy: 0.9159\n",
      "Epoch 4/10\n",
      "2447/2447 [==============================] - 1043s 426ms/step - loss: 0.0199 - accuracy: 0.9949 - val_loss: 0.1071 - val_accuracy: 0.9780\n",
      "Epoch 5/10\n",
      "2447/2447 [==============================] - 1050s 429ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.1050 - val_accuracy: 0.9769\n",
      "Epoch 6/10\n",
      "2447/2447 [==============================] - 895s 366ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.0540 - val_accuracy: 0.9869\n",
      "Epoch 7/10\n",
      "2447/2447 [==============================] - 978s 400ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.0831 - val_accuracy: 0.9779\n",
      "Epoch 8/10\n",
      "2447/2447 [==============================] - 636s 260ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.0926 - val_accuracy: 0.9775\n",
      "Epoch 9/10\n",
      "2447/2447 [==============================] - 435s 178ms/step - loss: 1.0846e-04 - accuracy: 0.9999 - val_loss: 0.0744 - val_accuracy: 0.9841\n",
      "Epoch 10/10\n",
      "2447/2447 [==============================] - 596s 244ms/step - loss: 1.9807e-07 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "earlystopping=callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                      mode='min',\n",
    "                                      patience=5,\n",
    "                                      restore_best_weights=True)\n",
    "\n",
    "history=model.fit(train,\n",
    "                  validation_data=eval,\n",
    "                  epochs=epochs,\n",
    "                  shuffle=True,\n",
    "                  verbose=1,\n",
    "                  callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\jupyternotebooks\\prototype 1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('D:\\jupyternotebooks\\prototype 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:01:15.058894\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3, 10,  0, 24, 15, 12, 20, 27, 21, 18, 11, 22, 28,  4,  6, 23,  9,\n",
       "       19, 13,  1, 14,  8, 25,  7,  2, 16, 17,  5], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=ImageDataGenerator(rescale=1./255).flow_from_directory(test_dir,target_size=(64,64),class_mode=None)\n",
    "pred=model.predict(test[0])\n",
    "pred = np.argmax(pred, axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 1 classes.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001198B8110D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model('D:\\jupyternotebooks\\prototype 1')\n",
    "dir=r\"D:\\jupyternotebooks\\test\"\n",
    "test=ImageDataGenerator(rescale=1./255).flow_from_directory(dir,target_size=(64,64),class_mode=None)\n",
    "pred=model.predict(test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
