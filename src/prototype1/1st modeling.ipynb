{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill \n",
    "dill.load_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(5)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2)\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import os \n",
    "import cv2\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=r\"D:\\jupyternotebooks\\prototype 1\\asl_alphabet_train\\asl_alphabet_train\"\n",
    "test_dir=r\"D:\\jupyternotebooks\\prototype 1\\asl_alphabet_test\\asl_alphabet_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the images from the directory \n",
    "def load_images(directory):\n",
    "    images=[]\n",
    "    labels=[]\n",
    "    for idx,label in enumerate(uniq_labels):\n",
    "        for file in os.listdir(directory+\"/\"+label):\n",
    "            filepath=directory+\"/\"+label+\"/\"+file\n",
    "            image = cv2.resize(cv2.imread(filepath), (64, 64))\n",
    "            images.append(image)\n",
    "            labels.append(idx)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_labels = sorted(os.listdir(train_dir))\n",
    "images, labels = load_images(directory = train_dir)\n",
    "\n",
    "if uniq_labels == sorted(os.listdir(test_dir)):\n",
    "    print(\"here\")\n",
    "    x_eval, y_eval = load_images(directory = test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(images,labels,test_size=0.1,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of signs in our dataset 29\n",
      "The total training images is 78300\n",
      "The total testing images is 8700\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of signs in our dataset {}\".format(len(uniq_labels)))\n",
    "print(\"The total training images is {}\".format(len(x_train)))\n",
    "print(\"The total testing images is {}\".format(len(x_test)))\n",
    "# print(\"The total evalution images is {}\".format(len(x_eval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print images using matplotlib\n",
    "def print_images(images_list):\n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('notebook_env.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
